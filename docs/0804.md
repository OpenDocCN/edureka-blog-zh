# 掌握了 Hadoop？是时候开始使用 Apache Spark 了

> 原文:[https://www . edu reka . co/blog/why-you-should-learn-spark-after-mastering-Hadoop](https://www.edureka.co/blog/why-you-should-learn-spark-after-mastering-hadoop)

Hadoop，众所周知是大数据的海报男孩。作为一个能够处理海量数据的软件框架，Hadoop 已经成为首席信息官的热门词汇。

然而，内存堆栈的空前崛起为大数据生态系统引入了一种新的分析替代方案。MapReduce 的分析方式正在被一种新的方法所取代，这种方法允许在 Hadoop 框架内外进行分析。Apache Spark 是大数据分析的新面孔。

大数据爱好者将 Apache Spark 认证为世界上最热门的大数据计算引擎。它正在迅速将 MapReduce 和 Java 从它们的位置上驱逐出去，工作趋势正在反映这种变化。根据 TypeSafe 的调查，全球 71%的 Java 开发者目前正在围绕 Spark 进行评估或研究，其中 35%已经开始使用。Spark 专家目前很受欢迎，在接下来的几周内，与 Spark 相关的工作机会预计将会大幅增加。

那么，是什么让 Apache Spark 出现在每个首席信息官的待办事项清单上呢？

以下是 Apache Spark 的一些有趣特性:

*   **Hadoop 集成**–Spark 可以处理存储在 HDFS 的文件。
*   **Spark 的交互 Shell**–Spark 是用 Scala 编写的，有自己版本的 Scala 解释器。
*   **Spark 的分析套件**–Spark 自带工具，用于交互式查询分析、大规模图形处理和分析以及实时分析。
*   **弹性分布式数据集(rdd)**–rdd 是可以跨计算节点集群缓存在内存中的分布式对象。它们是 Spark 中使用的主要数据对象。
*   **分布式操作符**——除了 MapReduce，还有许多其他操作符可以在 RDD 上使用。

像 NASA、Yahoo 和 Adobe 这样的组织都致力于 Spark。这是 Databricks 联盟和生态系统负责人 John Tripier 所说的话，“各行各业大大小小的企业对 Apache Spark 的采用正以令人难以置信的速度增长，对拥有认证专业知识的开发人员的需求也在迅速跟进”。如果你有 Hadoop 背景，现在是学习 Spark 的最佳时机。

Edureka 特别策划了一个关于 Apache Spark & Scala 的课程，由现实生活中的行业从业者共同创建。要获得与众不同的实时电子学习体验以及行业相关项目，请查看我们的课程。新一批即将开始，请在此查看课程:[【https://www.edureka.co/apache-spark-scala-training】](https://www.edureka.co/apache-spark-scala-training "Get started with Apache Spark and Scala")。

有问题要问我们吗？请在评论区提到它，我们会给你回复。

**相关帖子:**

[Apache Spark 和 Scala](https://www.edureka.co/apache-spark-scala-training "Get started with Apache Spark and Scala")T5】

[Apache Spark Vs Hadoop MapReduce](https://www.edureka.co/blog/apache-spark-vs-hadoop-mapreduce "Apache Spark Vs Hadoop MapReduce")