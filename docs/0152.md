# Apache MapReduce 和 HDFS 简介

> 原文：<https://www.edureka.co/blog/introduction-to-apache-hadoop-hdfs/>

## Apache MapReduce 和 HDFS 简介

Apache Hadoop 源自 Google 的白皮书:

1.  Apache HDFS 源自 GFS (Google 文件系统)。
2.  Apache MapReduce 源自 Google MapReduce
3.  Apache HBase 源自 Google BigTable。

虽然 Google 只提供了白皮书，但没有任何实现，这些白皮书中介绍的大约 90-95%的架构都应用在这三个基于 Java 的 Apache 项目中。

HDFS 和 MapReduce 是 Hadoop 的两个主要组件，其中 HDFS 是从“基础设施”的角度，而 MapReduce 是从“编程”的角度。虽然 HDFS 目前是 Apache Hadoop 的一个子项目，但它是作为 Apache Nutch web 搜索引擎项目的基础设施正式开发的。

为了理解 Hadoop 从单节点集群到一千节点集群的可伸缩性背后的魔力(Yahoo！拥有 4500 节点的集群管理 40pb 的企业数据)，我们需要先了解 Hadoop 的文件系统，也就是 HDFS (Hadoop 分布式文件系统)。

通过这个由来自大数据平台的顶级行业专家设计的[](https://www.edureka.co/big-data-hadoop-training-certification)大数据培训课程，探索和了解更多关于 HDFS 和 MapReduce 的知识。

#### 什么是 HDFS (Hadoop 分布式文件系统)？

HDFS 是一个分布式和可扩展的文件系统，设计用于存储具有流数据访问模式的超大型文件，在商用硬件上运行集群。

尽管它与现有的传统分布式文件系统有许多相似之处，但它们之间也有明显的差异。让我们看看 HDFS 背后的一些假设和目标，它们也形成了这个令人难以置信的文件系统的一些显著特征！

#### HDFS 背后的假设和目标:

#### 1.大型数据集:

人们认为 HDFS 总是需要处理大型数据集。如果部署 HDFS 来处理几个几兆甚至几十亿字节的小数据集，这将是一个低估。HDFS 的体系结构被设计成最适合存储和检索大量数据。需要的是高累积数据带宽和可伸缩性，以便从单个节点集群扩展到一百或一千个节点的集群。严峻的考验是 HDFS 应该能够一次管理数千万个文件。

#### 2.一次写入，多次读取模式:

HDFS 对其文件和应用程序采用一次写入多次读取的方法。它假设 HDFS 中的文件一旦写入就不会被修改，尽管它可以被访问‘n’次(尽管 Hadoop 的未来版本也可能支持这个特性)！目前，在 HDFS 任何时候都严格地有一个作家。这种假设实现了高吞吐量的数据访问，并且还简化了数据一致性问题。网络爬虫或 MapReduce 应用程序最适合 HDFS。

#### 3.流式数据访问:

由于 HDFS 的工作原则是“一次写入，多次读取”，因此流数据访问功能在 HDFS 极其重要。因为 HDFS 更多地是为批处理而不是用户交互使用而设计的。重点是数据访问的高吞吐量，而不是数据访问的低延迟。HDFS 关注的不是存储数据，而是如何以最快的速度检索数据，尤其是在分析日志时。在 HDFS，读取完整的数据比从数据中提取单个记录所花费的时间更重要。为了实现流数据访问，HDFS 忽略了一些 POSIX 要求。

#### 4.商用硬件:

HDFS (Hadoop 分布式文件系统)假设集群将在通用硬件上运行，即不昂贵的普通机器，而不是高可用性系统。Hadoop 的一个很大的特点是它可以安装在任何普通的商用硬件上。我们不需要超级计算机或高端硬件来在 Hadoop 上工作。这在很大程度上导致了总体成本的降低。

#### 5.数据复制和容错:

HDFS 的工作基于这样一种假设，即硬件在某个时间点肯定会出故障。这破坏了大量数据的平滑和快速处理。为了克服这一障碍，在 HDFS，文件被分成大的数据块，每个数据块存储在三个节点上:两个在同一个机架上，一个在不同的机架上，以便容错。块是存储在每个数据节点上的数据量。尽管默认的块大小是 64MB，复制因子是 3，但是这些都是可以针对每个文件进行配置的。这种冗余实现了健壮性、故障检测、快速恢复、可扩展性，消除了主机上的 RAID 存储需求，并具有数据局部性的优点。

#### 6.高吞吐量:

吞吐量是单位时间内完成的工作量。它描述了从系统中访问数据的速度，通常用于衡量系统的性能。在 Hadoop HDFS 中，当我们想要执行一项任务或一个动作时，工作会被划分并在不同的系统之间共享。因此，所有的系统都将独立并行地执行分配给它们的任务。所以这项工作将在很短的时间内完成。这样，阿帕奇 HDFS 提供了良好的吞吐量。通过并行读取数据，我们大大减少了读取数据的实际时间。

#### 7.移动计算比移动数据更好:

Hadoop HDFS 的工作原理是，如果应用程序在它所操作的数据附近进行计算，那么它比在远处进行计算要高效得多，尤其是当有大型数据集时。主要优点是减少了网络拥塞并增加了系统的总吞吐量。假设将计算放在离数据更近的地方通常比将数据移动到应用程序空间更好。为了促进这一点，Apache HDFS 为应用程序提供了接口，以便将它们自己重新定位到更靠近数据所在的位置。

#### 8.文件系统命名空间:

HDFS 遵循传统的分层文件组织，任何用户或应用程序都可以创建目录并将文件存储在这些目录中。因此，HDFS 的文件系统命名空间层次结构类似于大多数其他现有的文件系统，用户可以创建和删除文件，或者将文件从一个目录重新定位到另一个目录，甚至可以重命名文件。一般来说，HDFS 不支持硬链接或软链接，但如果需要的话可以实现。这些 Hadoop 工具和概念对于明确 **[大数据认证](https://www.edureka.co/blog/top-big-data-certifications)** 很重要。

因此，HDFS 致力于这些假设和目标，以帮助用户在极短的时间内访问或处理大型数据集！

在这篇文章中学习了“什么是 HDFS”之后，我们将进一步讨论构成 Hadoop 集群重要组成部分的 HDFS 组件！

有问题要问我们吗？在评论区提到它们，我们会给你回复。

相关帖子:

[大数据和 Hadoop 入门](https://www.edureka.co/big-data-and-hadoop)

[全面上手 MapReduce](https://www.edureka.co/comprehensive-mapreduce-self-paced)

[MapReduce 设计模式入门](https://www.edureka.co/mapreduce-design-patterns-sp)