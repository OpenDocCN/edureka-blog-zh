# 2023 年 Hadoop 管理面试问答

> 原文:[https://www . edu reka . co/blog/interview-questions/Hadoop-administration-interview-questions-and-answers/](https://www.edureka.co/blog/interview-questions/hadoop-administration-interview-questions-and-answers/)

为了通过面试，获得你梦想中的工作，做好准备是很重要的。这是实现这一目标的第一步。以下是一些常见的 Hadoop 管理面试问题和答案，可能会有用。

## **说出运行 Hadoop 集群所需的守护进程？T3】**

 <caption>#### **运行 Hadoop 集群所需的守护进程**</caption> 
| **守护进程** | **描述** |
| *DataNode* | 它将数据存储在 Hadoop 文件系统中，该文件系统包含多个 DataNode，并在它们之间复制数据 |
| ***NameNode**T3】* | 它是 HDFS 的核心，保持所有文件的目录树存在于文件系统中，并跟踪文件数据在集群中的保存位置 |
| ***SecondaryNameNode**T3】* | 它是 HDFS 集群中的一个专用节点，用于保存 namenode 上存在的文件系统元数据的检查点 |
| ***节点管理器*** | 它负责启动和管理节点上的容器，这些容器执行 AppMaster 指定的任务 |
| ***资源管理器*** | 主机通过仲裁所有可用的集群资源来帮助管理运行在 YARN 系统上的分布式应用 |

## **如何阅读来自 HDFS 的文件？**T3】

以下是执行此操作的步骤:

1.  客户端使用 Hadoop 客户端程序来发出请求。
2.  客户端程序读取本地机器上的集群配置文件，该文件告诉它 namemode 所在的位置。这必须提前配置。
3.  客户端联系 NameNode 并请求它想要读取的文件。
4.  客户端验证通过用户名或 Kerberos 等强身份验证机制进行检查。
5.  根据文件的所有者和权限检查客户端的验证请求。
6.  如果文件存在，并且用户可以访问它，那么 NameNode 用第一个块 id 响应，并提供一个 datanodes 列表。可以找到块的副本，按照它们到客户机(阅读器)的距离排序。
7.  客户端现在直接联系最合适的 datanode 并读取块数据。这个过程重复进行，直到文件中的所有块都被读取或者客户端关闭文件流。

如果在读取文件时 datanode 失效，库将自动尝试从另一个 datanode 读取数据的另一个副本。如果所有副本都不可用，读取操作将失败，客户端将收到异常。如果 NameNode 返回的关于数据块位置的信息在客户端尝试联系 datanode 时已经过时，如果有其他副本，将会重试，否则读取将会失败。在这个由大数据平台顶级行业专家设计的大数据课程中，探索和了解 HDFS。

## **解释 Hadoop 中的检查点及其重要性？**T3】

检查点是在 HDFS 维护和持久化文件系统元数据的重要部分。这对于高效的 Namenode 恢复和重启至关重要，并且是总体集群健康状况的重要指标。

Namenode 保存文件系统元数据。在高层次上，namenode 的主要职责是存储 HDFS 名称空间。也就是说，目录树、文件权限以及文件到块 id 的映射。为了容错，将这些元数据安全地保存到稳定的存储中是非常重要的。

这个文件系统元数据存储在两个不同的部分:fsimage 和编辑日志。fsimage 是一个代表文件系统元数据的时间点快照的文件。然而，虽然 fsimage 文件格式读起来非常有效，但它不适合进行小的增量更新，如重命名单个文件。因此，NameNode 不是在每次修改名称空间时都编写一个新的 fsimage，而是在编辑日志中记录修改操作以获得持久性。这样，如果 NameNode 崩溃，它可以通过首先加载 fsimage，然后重放编辑日志中的所有操作(也称为编辑或事务)来恢复其状态，以赶上名称系统的最新状态。编辑日志由一系列称为编辑日志段的文件组成，它们共同代表自创建 fsimage 以来对命名系统所做的所有修改。

## **HDFS 的默认块大小是多少？块大小更小有什么好处？**T3】

大多数块结构文件系统使用大约 4kb 或 8 KB 的块大小。相比之下，HDFS 的默认块大小是 64MB，甚至更大。这使得 HDFS 可以减少每个文件所需的元数据存储量。此外，通过将大量数据按顺序组织在磁盘上，它允许数据的快速流读取。因此，预计 HDFS 会有非常大的文件，这些文件是按顺序读取的。不像 NTFS 或 EXT 之类的文件系统有大量的小文件，HDFS 存储适度数量的非常大的文件:几百兆字节，或千兆字节。你甚至可以通过 [数据工程课程](https://www.edureka.co/microsoft-azure-data-engineering-certification-course) 了解大数据的细节。

## 帮助你与 HDFS 互动的两个主要模块是什么？它们有什么用途？T3】

user @ machine:Hadoop＄bin/Hadoop moduleName-cmdargs…

moduleName 告诉程序使用 Hadoop 功能的哪个子集。-cmd 是此模块中要执行的特定命令的名称。它的参数跟在命令名后面。

与 HDFS 系统相关的两个模块是:DFS 和 dfsadmin。

dfs 模块，也称为“FsShell”，提供基本的文件操作操作，并处理文件系统中的对象。dfsadmin 模块将文件系统作为一个整体来操作或查询。

## **如何设置 Hadoop 节点(数据节点/名称节点)使用多个卷/磁盘？**T3】

Datanodes 可以将数据块存储在通常位于不同本地磁盘驱动器上的多个目录中。为了设置多个目录，需要在配置参数下指定逗号分隔的路径名列表作为值，dfs.data.dir/dfs.datanode.data.dir.数据节点将尝试在每个目录中放置等量的数据。

Namenode 还支持多个目录，这些目录存储名称空间映像和编辑日志。为了设置多个目录，需要在配置参数 dfs.name.dir/dfs.namenode.data.dir.下指定逗号分隔的路径名列表作为值。命名节点目录用于命名空间数据复制，以便在其中一个磁盘出现故障时，可以从剩余的磁盘/卷中恢复映像和日志。

## **什么是调度器，Hadoop 集群中可以使用的三种调度器是什么？**T3】

调度器负责将任务分配给 tasktrackers 上的开放槽。调度程序是 jobtracker 中的一个插件。三种类型的调度程序是:

*   先进先出调度程序
*   公平调度程序
*   产能调度程序

从班加罗尔的[大数据课程中更好地了解 Hadoop 集群。](https://www.edureka.co/big-data-hadoop-training-certification-bangalore)

## 如何决定使用哪个调度程序？T3】

CS 调度程序可以在以下情况下使用:

*   当您非常了解您的集群工作负载和利用率，并且只想强制执行资源分配时。
*   当队列利用率波动很小时。当所有队列几乎总是满负荷时，CS 更严格的资源分配是有意义的。
*   当作业的内存需求差异很大，并且需要 CS 基于内存的调度支持时。
*   当您需要调度程序确定性时。

在以下情况下，公平调度程序可以优先于容量调度程序使用:

*   当您的网络速度较慢且数据局部性对作业运行时产生显著影响时，延迟调度等功能会对地图任务的有效局部性率产生显著影响。
*   当池之间的利用率有很大变化时，公平调度器的抢占模式会通过在不使用时放弃保留的资源来影响更大的整体集群利用率。
*   当您要求池中的作业取得相同的进度，而不是按 FIFO 顺序运行时。

## **为什么要用' dfs.name.dir '和' dfs.data.dir '参数？它们在哪里指定，如果不指定这些参数会发生什么？**T3】

DFS。指定 Namenode 的本地文件系统中存储 HDFS 元数据和 DFS 的目录路径。指定 Datanode 的本地文件系统中存储 HDFS 文件块的目录路径。这些参数在 HDFS 工厂指定。集群中所有节点的 XML 配置文件，包括主节点和从节点。

如果未指定这些参数，namenode 的元数据和 Datanode 的文件块相关信息将存储在 HADOOP-USERNAME 目录下的/tmp 中。这不是一个安全的地方，因为当节点重新启动时，数据将会丢失，而且如果 Namenode 重新启动，数据将是关键的，因为格式化信息将会丢失。

## **FSCK 的文件系统检查工具有什么用途？它显示了什么样的信息？FSCK 可以显示被客户端打开写入的文件的信息吗？**T3】

文件系统检查工具 FSCK 是用来检查和显示健康的文件系统，文件和块。当与路径(bin/Hadoop fsck/-files–blocks–locations-racks)一起使用时，它会递归显示该路径下所有文件的健康状况。当与'/'一起使用时，它检查整个文件系统。默认情况下，FSCK 会忽略客户端仍然打开进行写入的文件。要列出此类文件，请使用-openforwrite 选项运行 FSCK。

FSCK 检查文件系统，为每个发现健康的文件打印一个点，打印一条不健康文件的消息，包括有过度复制数据块、复制不足数据块、错误复制数据块、损坏数据块和丢失副本的文件。你甚至可以通过澳洲 [数据工程课程](https://www.edureka.co/microsoft-azure-data-engineering-certification-course-australia) 了解大数据的细节。

## **设置 Hadoop cluster 1.x 的全分布式模式(Apache distribution)需要更新/编辑哪些重要的配置文件？**T3】

设置 Hadoop 的完全分布式模式需要更新的配置文件有:

*   Hadoop-env.sh
*   核心网站. xml
*   Hdfs-site.xml
*   Mapred-site.xml
*   主人
*   奴隶

这些文件可以在您的 Hadoop>conf 目录中找到。如果使用“bin/Hadoop-daemon . sh start XXXXXX”单独启动 Hadoop 守护程序，其中 xxxx 是守护程序的名称，则主文件和从文件不需要更新，可以为空。这种启动守护程序的方式需要在适当的节点上发出命令来启动适当的守护程序。如果使用“bin/start-dfs.sh”和“bin/start-mapred.sh”启动 Hadoop 守护程序，则需要更新 namenode 计算机上的主配置文件和从配置文件。

masters–secondary name node 将运行的节点的 Ip 地址/主机名。

slaves–将运行 datanodes 和最终任务跟踪器的节点的 Ip 地址/主机名。

从 [Hadoop 管理课程](https://www.edureka.co/hadoop-administration-training-certification)中了解 Namenode、Datanode 和辅助 Namenode 的各种属性。

**万事如意！**

有问题要问我们吗？请在评论区提及它们，我们将会回复您。