# R 中随机森林综合指南

> 原文:[https://www.edureka.co/blog/random-forest-classifier/](https://www.edureka.co/blog/random-forest-classifier/)

## **随机森林中的 R:**

随着对更复杂计算的需求，我们不能依赖简单的算法。相反，我们必须利用具有更高计算能力的算法，随机森林就是这样一种算法。在这篇关于 R 中的随机森林的博客文章中，您将通过使用 [R 语言](https://www.edureka.co/blog/r-programming-language)学习随机森林的基础知识及其实现。

要获得深入的数据科学知识，您可以报名参加 Edureka 提供的实时 [*数据科学认证培训*](https://www.edureka.co/data-science) ，该培训提供全天候支持和终身访问。

以下是我将在 R 博客的这个随机森林中涉及的主题列表:

1.  [什么是分类？](#What%20is%20Classification)
2.  [什么是随机森林？](#What%20is%20Random%20Forest)
3.  [为什么使用随机森林？](#Why%20use%20Random%20Forest)
4.  [随机森林是如何工作的？](#How%20does%20Random%20Forest%20work)
5.  [创建随机森林](#Creating%20a%20Random%20Forest)
6.  R 中随机森林的实际实现

## **什么是分类？T3】**

分类是预测给定输入数据点的类别的方法。分类问题是机器学习中常见的问题，它们属于监督学习方法。

假设您想将您的电子邮件分为两类，垃圾邮件和非垃圾邮件。对于这类问题，您必须将输入数据点分配到不同的类中，您可以利用分类算法。

根据分类，我们有两种类型:

*   二元分类
*   多类分类

![Classification - Random Forest In R - Edureka](../Images/4979b84421053f9391e8716b368ae9dc.png)

*分类——R 中的随机森林——爱德华卡*

我之前给出的关于将电子邮件分类为垃圾邮件和非垃圾邮件的例子是二元类型的，因为这里我们将电子邮件分为两类(垃圾邮件和非垃圾邮件)。

但是，假设我们想将电子邮件分为 3 类:

*   垃圾邮件
*   非垃圾邮件
*   草稿

所以在这里，我们将电子邮件分为两类以上，这正是多类分类的意思。

这里还要注意的一点是，分类模型预测一个连续值是很常见的。但是这个连续值表示给定数据点属于每个输出类的概率。

既然你已经很好的理解了什么是分类，那我们就来看看机器学习中用到的几个[分类算法](https://www.edureka.co/blog/classification-algorithms/):

## **什么是随机森林？T3】**

随机森林算法是一种监督分类和回归算法。顾名思义，这个算法随机创建一个有几棵树的森林。

一般来说，森林里的树越多，森林看起来就越健壮。同样，在随机森林分类器中，森林中的树木数量越多，结果的准确性越高。

![Classification Random Forest - Random Forest In R - Edureka](../Images/35be62289d6c973d22635d1d3c620f25.png)

*随机森林——R 中的随机森林——爱德华卡*

简而言之，随机森林构建多个决策树(称为森林)，并将它们粘合在一起，以获得更准确和稳定的预测。它构建的森林是决策树的集合，用 bagging 方法训练。

在我们深入讨论随机森林之前，我们需要了解决策树是如何工作的。

你们很多人心里都有这个问题:

## **随机森林和决策树有什么区别？T3】**

让我解释一下。

假设你想买一栋房子，但是你无法决定买哪一栋。所以，你咨询了几个中介，他们给了你一个你在买房前应该考虑的参数清单。该列表包括:

*   房子的价格
*   位置
*   卧室数量
*   停车位
*   可用设施

这些参数被称为*预测变量*，用于寻找响应变量。下面是一个图解，说明如何使用决策树来表达上述问题陈述。

![Decision Tree Example - Random Forest In R - Edureka](../Images/d280456808c4a944fb0257cda6cdfd4a.png)

*决策树示例——R 中的随机森林——爱德华卡*

这里需要注意的重要一点是，决策树是建立在整个数据集上的，利用了所有的预测变量。现在让我们看看随机森林如何解决同样的问题。

就像我前面提到的，随机森林是决策树的集合，它随机选择一组参数，并为每组选择的参数创建一个决策树。

请看下图。

![Random Forest With 3 Decision Trees - Random Forest In R - Edureka](../Images/b0dec519894292fec81606377e5e402f.png)

*有 3 棵决策树的随机森林——R 中的随机森林——爱德华卡*

在这里，我创建了 3 个决策树，每个决策树只从整个数据集中获取 3 个参数。每个决策树基于该树中使用的相应预测变量来预测结果，最后取随机森林中所有决策树的结果的平均值。

简而言之，使用这种方法创建多个决策树后，每棵树选择或投票给该类(在这种情况下，决策树将选择是否买房)，以简单多数获得最多投票的类称为预测类。

总之，决策树是使用所有预测变量在整个数据集上构建的，而随机森林用于创建多个决策树，使得每个决策树仅在数据集的一部分上构建。

我希望决策树和随机森林的区别是清楚的。

## **为什么要用随机森林？T3】**

你可能想知道，当我们可以使用决策树解决同样的问题时，为什么还要使用随机森林。让我解释一下。

*   尽管决策树很方便且容易实现，但它们缺乏准确性。决策树在处理用于构建它们的训练数据时非常有效，但在对新样本进行分类时却不灵活。这意味着测试阶段的精确度非常低。
*   这是由于一个叫做过度拟合的过程造成的。

*Over-fitting occurs when a model studies the training data to such an extent that it negatively influences the performance of the model on new data.*

***   这意味着训练数据中的扰动被模型记录和学习为概念。但这里的问题是，这些概念不适用于测试数据，并对模型分类新数据的能力产生负面影响，因此降低了测试数据的准确性。**

**这就是随机森林的用武之地。它基于 bagging 的思想，bagging 用于通过组合数据集的不同样本上的多个决策树的结果来减少预测中的变化。**

**现在我们来关注一下随机森林。**

## ****随机森林是如何工作的？T3】****

**为了理解随机森林，考虑下面的样本数据集。在这个数据集中，我们有四个预测变量，即:**

***   重量*   血流*   动脉阻塞*   胸部疼痛**

**![Sample Data Set - Random Forest In R - Edureka](../Images/419b554b2759adda4766fb49b8ea4f7d.png)**

***样本数据集——R 中的随机森林——爱德华卡***

**这些变量被用来预测一个人是否患有心脏病。我们将使用这个数据集来创建一个随机森林，预测一个人是否患有心脏病。**

## ****创建随机森林****

*****第一步:创建自举数据集*****

**Bootstrapping 是一种估计方法，用于通过对数据集进行重新采样来对其进行预测。为了创建自举数据集，我们必须从原始数据集中随机选择样本。这里需要注意的一点是，我们可以多次选择同一个样本。**

**![Bootstrapped Data Set - Random Forest In R - Edureka](../Images/099645132c05b56b204453de480f6660.png)**

***自举数据集——R 中的随机森林——爱德华卡***

**在上图中，我从原始数据集中随机选择了样本，并创建了一个自举数据集。很简单，不是吗？在现实世界的问题中，你永远不会得到这么小的数据集，因此创建一个自举数据集要稍微复杂一些。**

*****步骤二:创建决策树*****

***   我们的下一个任务是通过使用上一步中创建的引导数据集来构建决策树。因为我们正在创建一个随机森林，所以我们不会考虑我们创建的整个数据集，相反，我们将在每个步骤中只使用一个随机变量子集。*   在这个例子中，我们每一步只考虑两个变量。所以，我们从根节点开始，这里我们随机选择两个变量作为根节点的候选变量。*   假设我们选择了血流并阻塞了动脉。在这两个变量中，我们现在必须选择最能区分样本的变量。为了这个例子，假设阻塞的动脉是更重要的预测器，因此将其指定为根节点。*   我们的下一步是对每个即将到来的分支节点重复相同的过程。这里，我们再次随机选择两个变量作为分支节点的候选变量，然后选择一个最能分离样本的变量。**

**就像这样，我们通过在每一步只考虑变量的随机子集来构建树。按照上面的过程，我们的树看起来会像这样:**

**![Random Forest Algorithm - Random Forest In R - Edureka](../Images/7e26e02dfd3bb2e4b0a27cc06b44aebd.png)**

***随机森林算法——R 中的随机森林——爱德华卡***

**我们刚刚创建了第一个决策树。**

*****第三步:回到第一步，重复*****

**就像我前面提到的，随机森林是决策树的集合。每个决策树基于该树中使用的相应预测变量来预测输出类。最后，记录随机森林中所有决策树的结果，并计算具有多数投票的类作为输出类。**

**因此，我们现在必须通过在每一步考虑随机预测变量的子集来创建更多的决策树。为此，请返回到步骤 1，创建一个新的引导数据集，然后通过在每个步骤只考虑变量的子集来构建决策树。因此，按照上面的步骤，我们的随机森林看起来会像这样:**

**![Random Forest - Random Forest In R - Edureka](../Images/877a1cd5bf2c496ef5c90b092a2f2f80.png)**

***随机森林——R 中的随机森林——爱德华卡***

**这种迭代执行 100 次，因此通过在每个步骤使用随机选择的变量的子集，创建多个决策树，每个树计算输出。**

**在随机森林中拥有如此多样的决策树，比使用所有特征和整个数据集创建的单个决策树更有效。**

*****第四步:预测新数据点的结果*****

**现在我们已经创建了一个随机森林，让我们看看如何用它来预测一个新患者是否患有心脏病。下图显示了新患者的数据。我们要做的就是沿着我们做的决策树运行这些数据。**

**第一棵树显示患者患有心脏病，因此我们在如图所示的表格中对其进行跟踪。**

**![Output - Random Forest In R - Edureka](../Images/0ee77ed1fbc8fa8ee306ea18ffc3c092.png)**

***输出–R 中的随机森林–爱德华卡***

**类似地，我们沿着其他决策树运行这些数据，并跟踪每棵树预测的类别。在运行随机森林中所有树的数据后，我们检查哪个类得到了多数票。在我们的例子中,“是”类获得了最多的票数，因此很明显新病人患有心脏病。**

***总之，我们引导数据并使用所有树的集合来做决定，这个过程被称为装袋。***

*****第五步:评估模型*****

**我们的最后一步是评估随机森林模型。之前在创建引导数据集时，我们忽略了一个条目/样本，因为我们复制了另一个样本。在现实世界的问题中，大约 1/3 的原始数据集没有包含在自举数据集中。**

**下图显示了没有出现在引导数据集中的条目。**

**![Out-Of-Bag Sample - Random Forest In R - Edureka](../Images/2e396bb1b259272c94c2179a45e8aa11.png)**

***随机抽样——R 中的随机森林——爱德华卡***

**不包括在自举数据集中的这个样本数据集被称为开箱(OOB)数据集。**

***The Out-Of-Bag data set is used to check the accuracy of the model, since the model wasn’t created using this OOB data it will give us a good understanding of whether the model is effective or not.***

****在我们的例子中，OOB 数据集的输出类是“No”。因此，为了让我们的随机森林模型准确，如果我们沿着决策树运行 OOB 数据，我们必须得到大多数“不”票。对所有 OOB 样本执行此过程，在我们的情况下，我们只有一个 OOB，然而，在大多数问题中，通常有更多的样本。****

****因此，最终，我们可以通过正确分类的 OOB 样本的比例来衡量随机森林的准确性。****

****被错误分类的 OOB 样本的比例被称为袋外误差。这就是随机森林如何工作的一个例子。****

****现在让我们动手实现随机森林算法来解决一个更复杂的问题。****

## ******R 中随机森林的实际实现******

****即使生活在岩石下的人也会听说过一部叫《泰坦尼克号》的电影。但是你们中有多少人知道这部电影是根据真实事件改编的？Kaggle 收集了一组数据，包括泰坦尼克号上的幸存者和死者。****

******问题陈述:**建立一个随机森林模型，该模型可以研究泰坦尼克号上某个人的特征，并预测他们幸存的可能性。****

******数据集描述:**每个人的数据集中有几个变量/特征:****

*****   乘客等级(一等、二等或三等)*   性*   年龄*   sibsp:船上的兄弟姐妹/配偶人数*   parch:船上父母/子女人数*   票价:乘客付了多少钱*   上船:他们上船的地方(C =瑟堡；Q =皇后镇；S =南安普敦****

****我们将使用 RStudio 在 R 中运行下面的代码片段，所以请打开 RStudio。对于这个演示，您需要安装 caret 包和 randomForest 包。****

```
****install.packages("caret", dependencies = TRUE)
install.packages("randomForest")**** 
```

****下一步是将包加载到工作环境中。****

```
****library(caret)
library(randomForest)**** 
```

****是时候加载数据了，我们将使用 read.table 函数来完成这项工作。确保您提到了文件的路径(train.csv 和 test.csv)****

```
****train <- read.table('C:/Users/zulaikha/Desktop/titanic/train.csv', sep=",", header= TRUE)**** 
```

****上面的命令读入文件“train.csv”，使用分隔符“，”，包括标题行作为列名，并将其分配给 R 对象 train。****

****现在，让我们读入测试数据:****

```
****test <- read.table('C:/Users/zulaikha/Desktop/titanic/test.csv', sep = ",", header = TRUE)**** 
```

****为了比较训练和测试数据，让我们看一下训练集的前几行:****

```
****head(train)**** 
```

****![Training Data - Random Forest In R - Edureka](../Images/04eedb1bca1426b0a13afa8bb657ee2c.png)****

*****训练数据——R 中的随机森林——爱德华卡*****

****你会注意到每一行都有一列“幸存”，这是一个介于 0 和 1 之间的概率，如果这个人幸存下来，这个值大于 0.5，如果他们没有，这个值小于 0.5。现在，让我们比较一下训练集和测试集:****

```
****head(test)**** 
```

****![Testing Data - Random Forest In R - Edureka](../Images/7b941ca0e4a4979eb9635d4f5a3064e6.png)****

*****测试数据——R 中的随机森林——爱德华卡*****

****训练集和测试集的主要区别在于训练集是有标签的，而测试集是无标签的。火车场景显然没有“幸存”一栏，因为我们必须预测每一个登上泰坦尼克号的人。****

****在我们进一步深入之前，构建模型时最重要的因素是，选择在模型中使用的最佳特性。这绝不是挑选最好的算法或使用最复杂的 R 包。现在，“特征”只是一个变量。****

****所以，这给我们带来了一个问题，我们如何选择最重要的变量来使用？最简单的方法是使用交叉表和条件盒图。****

****交叉标签以可理解的方式表示两个变量之间的关系。根据我们的问题，我们想知道哪些变量是“幸存”的最佳预测值。让我们看看“幸存”和其他变量之间的交叉标签。在 R 中，我们使用表函数:****

```
****table(train[,c('Survived', 'Pclass')])
        Pclass
Survived   1   2   3
       0  80  97 372
       1 136  87 119**** 
```

****从交叉表中，我们可以看到“Pclass”可能是一个有用的“存活”预测值这是因为，交叉表的第一列显示，在一等舱的乘客中，136 人幸存，80 人死亡(即 63%的一等舱乘客幸存)。另一方面，在二等舱，87 人幸存，97 人死亡(即只有 47%的二等舱乘客幸存)。最后，在三等舱，119 人幸存，372 人死亡(即只有 24%的三等舱乘客幸存)。这意味着乘客等级和生存机会之间有明显的关系。****

****现在我们知道必须在我们的模型中使用 Pclass，因为它对于某人是否幸存无疑具有很强的预测价值。现在，您可以对数据集中的其他分类变量重复这一过程，并决定要包括哪些变量****

****为了使事情变得简单，让我们使用“条件”箱线图来比较每个连续变量的分布，条件是乘客是否幸存。但首先我们需要安装“字段”包:****

```
****install.packages("fields")
library(fields)
bplot.xy(train$Survived, train$Age)**** 
```

****![BoxPlot - Random Forest In R - Edureka](../Images/6bc7443e5b5db607a3ba073d7b06b535.png)****

*****方块图——R 中的随机森林——爱德华卡*****

****幸存者和幸存者的年龄方框图几乎是一样的。这意味着一个人的年龄对一个人是否存活没有很大的影响。y 轴是年龄，x 轴是存活。****

****还有，总结一下，NA 的多了去了。所以，让我们排除年龄这个变量，因为它对幸存下来的人没有太大的影响，而且因为 NA 的存在使它很难工作。****

```
****summary(train$Age)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
   0.42   20.12   28.00   29.70   38.00   80.00     177**** 
```

****在下面的箱线图中，幸存者和幸存者的票价箱线图有很大的不同。同样，y 轴是 Fare，x 轴是 Survived。****

```
****bplot.xy(train$Survived, train$Fare)**** 
```

****![BoxPlot For Fair - Random Forest In R - Edureka](../Images/7e0a1db121fd8b8d0d593c6a80c7e64e.png)****

*****R–edu reka*公平随机森林的箱线图****

****总结一下，你会发现没有 NA 的费用。所以，让我们把这个变量包括进去。****

```
****summary(train$Fare)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   0.00    7.91   14.45   32.20   31.00  512.33**** 
```

****下一步是将 Survived 转换为 Factor 数据类型，以便 caret 构建分类而不是回归模型。之后，我们使用一个简单的训练命令来训练模型。****

****现在，使用我们之前讨论过的随机森林算法来训练该模型。随机森林非常适合这类问题，因为它可以执行大量的计算，并以很高的精度预测结果。****

```
****# Converting &lsquo;Survived&rsquo; to a factor
train$Survived <- factor(train$Survived)
# Set a random seed
set.seed(51)
# Training using &lsquo;random forest&rsquo; algorithm
model <- train(Survived ~ Pclass + Sex + SibSp +
Embarked + Parch + Fare, # Survived is a function of the variables we decided to include
data = train, # Use the train data frame as the training data
method = 'rf',# Use the 'random forest' algorithm
trControl = trainControl(method = 'cv', # Use cross-validation
number = 5) # Use 5 folds for cross-validation**** 
```

****为了评估我们的模型，我们将使用交叉验证分数。****

****交叉验证用于通过使用训练数据来评估模型的效率。首先，将训练数据随机分成 5 个大小相等的部分，称为“折叠”。接下来，您对 4/5 的数据训练模型，并对您遗漏的 1/5 的数据检查其准确性。然后，对每个数据分割重复这个过程。最后，对五个不同的数据分割的百分比准确度进行平均，得到一个平均准确度。Caret 为您完成了这项工作，您可以通过查看模型输出来查看分数:****

```
****model
Random Forest 

891 samples
  6 predictor
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 712, 713, 713, 712, 714 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
  2     0.8047116  0.5640887
  5     0.8070094  0.5818153
  8     0.8002236  0.5704306

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 5.**** 
```

****首先要注意的是它说，“用于模型的最终值是 mtry = 5。”“mtry”是随机森林模型的超参数，它决定了模型使用多少变量来分割树。****

****该表显示了 mtry 的不同值及其在交叉验证下的相应平均准确度。Caret 自动挑选交叉验证下最准确的超参数“mtry”的值。****

****在 mtry = 5 的输出中，平均精度为 0.8170964，约为 82%。这是最高的值，因此 Caret 为我们选择了这个值。****

****在我们预测测试数据的输出之前，让我们检查一下在我们用来预测的变量中是否有任何缺失的数据。如果 Caret 发现任何缺少的值，它将不会返回任何预测。因此，我们必须在继续之前找到缺失的数据:****

```
****summary(test)**** 
```

****![Summary of the Test Data - Random Forest In R - Edureka](../Images/4693b0041ab1fb1ea7657f263db7dec7.png)****

*****测试数据汇总——R-edu reka*随机森林****

****注意变量“Fare”有一个 NA 值。让我们用“Fare”列含义来填写该值。我们使用 if-else 语句来实现这一点。****

****因此，如果“Fare”列中的条目是 NA，则用该列的平均值替换它，并在取平均值时去掉 NA:****

```
****test$Fare <- ifelse(is.na(test$Fare), mean(test$Fare, na.rm = TRUE), test$Fare)**** 
```

****现在，我们的最后一步是在测试集上进行预测。为此，您只需对您训练的模型对象调用 predict 方法。让我们在测试集上进行预测，并将它们添加为一个新列。****

```
****test$Survived <- predict(model, newdata = test)**** 
```

****最后，它输出对测试数据的预测，****

```
****test$Survived**** 
```

****![Predicting Outcome - Random Forest In R - Edureka](../Images/19b00bb9d819754af51b909545bc6bc6.png)****

*****预测结果——R 中的随机森林——爱德华卡*****

****在这里，您可以看到每个乘客的“幸存”值(0 或 1)。其中 1 代表幸存，0 代表死亡。这一预测是基于“pclass”和“Fare”变量做出的。你也可以使用其他变量，如果它们与登上泰坦尼克号的人能否幸存有关。****

****既然你已经知道了随机森林是如何工作的，我相信你一定很想了解更多关于各种机器学习算法的知识。这里有一个博客列表，深入涵盖了不同类型的机器学习算法****

*****   [线性回归](https://www.edureka.co/blog/linear-regression-in-r/)*   [逻辑回归](https://www.edureka.co/blog/logistic-regression-in-r/)*   [支持向量机](https://www.edureka.co/blog/support-vector-machine-in-r/)*   [决策树](https://www.edureka.co/blog/decision-trees/)*   [K-表示](https://www.edureka.co/blog/k-means-clustering-algorithm/)****

****就这样，我们结束了这篇博客。我希望你们都觉得这篇博客内容丰富。如果你有任何想法分享，请在下面评论。敬请关注更多类似的博客！****

*****如果你正在寻找数据科学的在线结构化培训，edureka！拥有专门策划的[数据科学课程](https://www.edureka.co/data-science)，帮助你获得统计学、数据争论、探索性数据分析、机器学习算法(如 K 均值聚类、决策树、随机森林、朴素贝叶斯)方面的专业知识。您将学习时间序列的概念、文本挖掘以及深度学习的介绍。本课程的新批次即将开始！！*****